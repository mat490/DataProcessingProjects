{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Traffic Accident Injury Prediction\n",
    "This project aims to predict the total number of injuries in a traffic accident using machine learning models. The dataset, sourced from Kaggle, contains detailed information on traffic accidents across various regions and time periods. It includes accident-related features such as weather conditions, lighting conditions, crash types, and vehicle involvement.\n",
    "\n",
    "The data preprocessing pipeline includes:\n",
    "* Handling missing values (imputation).\n",
    "* Standardizing numerical features.\n",
    "* Encoding categorical variables using one-hot encoding.\n",
    "\n",
    "To find the best model, several regression models were trained, including:\n",
    "* Linear Regression\n",
    "* Decision Tree Regressor\n",
    "* Random Forest Regressor\n",
    "\n",
    "The models are evaluated using Root Mean Squared Error (RMSE), and cross-validation is applied to assess their generalization performance. The final trained model can be used to estimate the expected number of injuries in future traffic accidents..\n",
    "\n",
    "Data is from Oktay Ördekçi Kaggle repository:\n",
    "https://www.kaggle.com/datasets/oktayrdeki/traffic-accidents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading data\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "def loadData():\n",
    "    return pd.read_csv(Path('./data/traffic_accidents.csv'))\n",
    "\n",
    "accidentsData = loadData()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 209306 entries, 0 to 209305\n",
      "Data columns (total 24 columns):\n",
      " #   Column                         Non-Null Count   Dtype  \n",
      "---  ------                         --------------   -----  \n",
      " 0   crash_date                     209306 non-null  object \n",
      " 1   traffic_control_device         209306 non-null  object \n",
      " 2   weather_condition              209306 non-null  object \n",
      " 3   lighting_condition             209306 non-null  object \n",
      " 4   first_crash_type               209306 non-null  object \n",
      " 5   trafficway_type                209306 non-null  object \n",
      " 6   alignment                      209306 non-null  object \n",
      " 7   roadway_surface_cond           209306 non-null  object \n",
      " 8   road_defect                    209306 non-null  object \n",
      " 9   crash_type                     209306 non-null  object \n",
      " 10  intersection_related_i         209306 non-null  object \n",
      " 11  damage                         209306 non-null  object \n",
      " 12  prim_contributory_cause        209306 non-null  object \n",
      " 13  num_units                      209306 non-null  int64  \n",
      " 14  most_severe_injury             209306 non-null  object \n",
      " 15  injuries_total                 209306 non-null  float64\n",
      " 16  injuries_fatal                 209306 non-null  float64\n",
      " 17  injuries_incapacitating        209306 non-null  float64\n",
      " 18  injuries_non_incapacitating    209306 non-null  float64\n",
      " 19  injuries_reported_not_evident  209306 non-null  float64\n",
      " 20  injuries_no_indication         209306 non-null  float64\n",
      " 21  crash_hour                     209306 non-null  int64  \n",
      " 22  crash_day_of_week              209306 non-null  int64  \n",
      " 23  crash_month                    209306 non-null  int64  \n",
      "dtypes: float64(6), int64(4), object(14)\n",
      "memory usage: 38.3+ MB\n"
     ]
    }
   ],
   "source": [
    "# A very short view of the data\n",
    "accidentsData.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\matsu\\AppData\\Local\\Temp\\ipykernel_7260\\1595761431.py:2: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  accidentsData['crash_date'] = pd.to_datetime(accidentsData['crash_date'], errors='coerce')\n"
     ]
    }
   ],
   "source": [
    "# Date transformation\n",
    "accidentsData['crash_date'] = pd.to_datetime(accidentsData['crash_date'], errors='coerce')\n",
    "accidentsData['crash_year'] = accidentsData['crash_date'].dt.year\n",
    "accidentsData['crash_month'] = accidentsData['crash_date'].dt.month\n",
    "accidentsData['crash_day_of_week'] = accidentsData['crash_date'].dt.dayofweek\n",
    "\n",
    "accidentsData = accidentsData.drop(columns=['crash_date'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing Pipelines\n",
    "\n",
    "To handle different types of data effectively, we create separate preprocessing pipelines for **numerical** and **categorical** features.\n",
    "\n",
    "### 1. **Numerical Pipeline**\n",
    "The numerical pipeline performs the following steps:\n",
    "- **Imputation**: Replaces missing values with the **median** of the column.\n",
    "- **Scaling**: Standardizes numerical features using **StandardScaler**, which ensures that each feature has a mean of 0 and a standard deviation of 1.\n",
    "\n",
    "### 2. **Categorical Pipeline**\n",
    "The categorical pipeline processes categorical data using:\n",
    "\n",
    "* Imputation: Fills missing values with the most frequent category.\n",
    "* One-Hot Encoding: Converts categorical variables into numerical format using OneHotEncoder, ignoring unknown categories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import make_pipeline, Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, FunctionTransformer\n",
    "num_pipeline = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "cat_pipeline = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Transformation with `make_column_transformer`\n",
    "\n",
    "To apply different preprocessing steps to **numerical** and **categorical** features, we use `make_column_transformer`. This allows us to automatically select and transform columns based on their data type.\n",
    "\n",
    "### **Building the Preprocessing Pipeline**\n",
    "We use `make_column_transformer` to combine:\n",
    "- The **numerical pipeline** (`num_pipeline`) for columns with numerical data.\n",
    "- The **categorical pipeline** (`cat_pipeline`) for columns with categorical data.\n",
    "\n",
    "### How It Works:\n",
    "* make_column_selector(dtype_include=np.number): Automatically selects numerical columns.\n",
    "* make_column_selector(dtype_include=object): Automatically selects categorical columns.\n",
    "* The preprocessing pipeline ensures that all features are properly processed before feeding them into a machine learning model.\n",
    "\n",
    "This automated feature transformation simplifies data preprocessing, making it more flexible and scalable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.compose import make_column_selector, make_column_transformer\n",
    "import numpy as np\n",
    "preprocessing = make_column_transformer(\n",
    "    (num_pipeline, make_column_selector(dtype_include=np.number)),\n",
    "    (cat_pipeline, make_column_selector(dtype_include=object))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the preprocessing pipeline to the dataset.\n",
    "# This transforms numerical features (imputation + scaling) and encodes categorical features.\n",
    "# The output is a NumPy array with the processed data.\n",
    "accidentsData_prepared = preprocessing.fit_transform(accidentsData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pipeline-1__num_units</th>\n",
       "      <th>pipeline-1__injuries_total</th>\n",
       "      <th>pipeline-1__injuries_fatal</th>\n",
       "      <th>pipeline-1__injuries_incapacitating</th>\n",
       "      <th>pipeline-1__injuries_non_incapacitating</th>\n",
       "      <th>pipeline-1__injuries_reported_not_evident</th>\n",
       "      <th>pipeline-1__injuries_no_indication</th>\n",
       "      <th>pipeline-1__crash_hour</th>\n",
       "      <th>pipeline-1__crash_day_of_week</th>\n",
       "      <th>pipeline-1__crash_month</th>\n",
       "      <th>...</th>\n",
       "      <th>pipeline-2__prim_contributory_cause_TURNING RIGHT ON RED</th>\n",
       "      <th>pipeline-2__prim_contributory_cause_UNABLE TO DETERMINE</th>\n",
       "      <th>pipeline-2__prim_contributory_cause_UNDER THE INFLUENCE OF ALCOHOL/DRUGS (USE WHEN ARREST IS EFFECTED)</th>\n",
       "      <th>pipeline-2__prim_contributory_cause_VISION OBSCURED (SIGNS, TREE LIMBS, BUILDINGS, ETC.)</th>\n",
       "      <th>pipeline-2__prim_contributory_cause_WEATHER</th>\n",
       "      <th>pipeline-2__most_severe_injury_FATAL</th>\n",
       "      <th>pipeline-2__most_severe_injury_INCAPACITATING INJURY</th>\n",
       "      <th>pipeline-2__most_severe_injury_NO INDICATION OF INJURY</th>\n",
       "      <th>pipeline-2__most_severe_injury_NONINCAPACITATING INJURY</th>\n",
       "      <th>pipeline-2__most_severe_injury_REPORTED, NOT EVIDENT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.159843</td>\n",
       "      <td>-0.478565</td>\n",
       "      <td>-0.039126</td>\n",
       "      <td>-0.162855</td>\n",
       "      <td>-0.359765</td>\n",
       "      <td>-0.269518</td>\n",
       "      <td>0.60910</td>\n",
       "      <td>-0.066570</td>\n",
       "      <td>1.037877</td>\n",
       "      <td>0.066571</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.159843</td>\n",
       "      <td>-0.478565</td>\n",
       "      <td>-0.039126</td>\n",
       "      <td>-0.162855</td>\n",
       "      <td>-0.359765</td>\n",
       "      <td>-0.269518</td>\n",
       "      <td>-0.19659</td>\n",
       "      <td>-2.386418</td>\n",
       "      <td>1.553809</td>\n",
       "      <td>0.358322</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 158 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   pipeline-1__num_units  pipeline-1__injuries_total  \\\n",
       "0              -0.159843                   -0.478565   \n",
       "1              -0.159843                   -0.478565   \n",
       "\n",
       "   pipeline-1__injuries_fatal  pipeline-1__injuries_incapacitating  \\\n",
       "0                   -0.039126                            -0.162855   \n",
       "1                   -0.039126                            -0.162855   \n",
       "\n",
       "   pipeline-1__injuries_non_incapacitating  \\\n",
       "0                                -0.359765   \n",
       "1                                -0.359765   \n",
       "\n",
       "   pipeline-1__injuries_reported_not_evident  \\\n",
       "0                                  -0.269518   \n",
       "1                                  -0.269518   \n",
       "\n",
       "   pipeline-1__injuries_no_indication  pipeline-1__crash_hour  \\\n",
       "0                             0.60910               -0.066570   \n",
       "1                            -0.19659               -2.386418   \n",
       "\n",
       "   pipeline-1__crash_day_of_week  pipeline-1__crash_month  ...  \\\n",
       "0                       1.037877                 0.066571  ...   \n",
       "1                       1.553809                 0.358322  ...   \n",
       "\n",
       "   pipeline-2__prim_contributory_cause_TURNING RIGHT ON RED  \\\n",
       "0                                                0.0          \n",
       "1                                                0.0          \n",
       "\n",
       "   pipeline-2__prim_contributory_cause_UNABLE TO DETERMINE  \\\n",
       "0                                                1.0         \n",
       "1                                                0.0         \n",
       "\n",
       "   pipeline-2__prim_contributory_cause_UNDER THE INFLUENCE OF ALCOHOL/DRUGS (USE WHEN ARREST IS EFFECTED)  \\\n",
       "0                                                0.0                                                        \n",
       "1                                                0.0                                                        \n",
       "\n",
       "   pipeline-2__prim_contributory_cause_VISION OBSCURED (SIGNS, TREE LIMBS, BUILDINGS, ETC.)  \\\n",
       "0                                                0.0                                          \n",
       "1                                                0.0                                          \n",
       "\n",
       "   pipeline-2__prim_contributory_cause_WEATHER  \\\n",
       "0                                          0.0   \n",
       "1                                          0.0   \n",
       "\n",
       "   pipeline-2__most_severe_injury_FATAL  \\\n",
       "0                                   0.0   \n",
       "1                                   0.0   \n",
       "\n",
       "   pipeline-2__most_severe_injury_INCAPACITATING INJURY  \\\n",
       "0                                                0.0      \n",
       "1                                                0.0      \n",
       "\n",
       "   pipeline-2__most_severe_injury_NO INDICATION OF INJURY  \\\n",
       "0                                                1.0        \n",
       "1                                                1.0        \n",
       "\n",
       "   pipeline-2__most_severe_injury_NONINCAPACITATING INJURY  \\\n",
       "0                                                0.0         \n",
       "1                                                0.0         \n",
       "\n",
       "   pipeline-2__most_severe_injury_REPORTED, NOT EVIDENT  \n",
       "0                                                0.0     \n",
       "1                                                0.0     \n",
       "\n",
       "[2 rows x 158 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Wrapping accidentsData_prepared in a Pandas DataFrame\n",
    "accidentsData_prepared = pd.DataFrame(\n",
    "    accidentsData_prepared.toarray(),\n",
    "    columns=preprocessing.get_feature_names_out(),\n",
    "    index=accidentsData.index\n",
    ")\n",
    "accidentsData_prepared.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "# Split the dataset into training and testing sets.\n",
    "# 80% of the data is used for training, and 20% for testing.\n",
    "# The random_state is set to ensure reproducibility of the split.\n",
    "train_set, test_set = train_test_split(accidentsData_prepared, test_size=0.2, random_state=42)\n",
    "\n",
    "# Split the training data into features (accidentsTrain) and labels (accidentsTrain_labels)\n",
    "# 'pipeline-1__injuries_total' is the target variable (number of injuries).\n",
    "# We drop the target variable from the features and store it separately as the label.\n",
    "accidentsTrain = train_set.drop(\"pipeline-1__injuries_total\", axis=1)  # Features without the target variable\n",
    "accidentsTrain_labels = train_set['pipeline-1__injuries_total'].copy()   # The target variable (number of injuries)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training and Comparing Machine Learning Models\n",
    "\n",
    "In this section, we train multiple machine learning models to predict the total number of injuries in traffic accidents and compare their performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. **Linear Regression**\n",
    "\n",
    "Linear Regression is a simple yet powerful model used for predicting continuous variables. It is trained on the training set and its predictions are evaluated using Root Mean Squared Error (RMSE)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "lin_reg = make_pipeline(preprocessing, LinearRegression())\n",
    "lin_reg.fit(accidentsTrain, accidentsTrain_labels)\n",
    "predictions = lin_reg.predict(accidentsTrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.3256252688793172e-13"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import the root mean squared error (RMSE) function from sklearn.metrics\n",
    "from sklearn.metrics import root_mean_squared_error\n",
    "\n",
    "# Calculate the RMSE between the true labels (accidentsTrain_labels) and the predictions made by the model\n",
    "# RMSE gives an idea of how far off the model's predictions are from the actual values\n",
    "lin_rmse = root_mean_squared_error(accidentsTrain_labels, predictions)\n",
    "\n",
    "# Output the RMSE value for the linear regression model\n",
    "lin_rmse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Decision Tree Regressor\n",
    "Decision Tree Regressor is a non-linear model that works well for capturing complex relationships between features. We also evaluate its performance using RMSE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "# Initialize the decision tree regressor model\n",
    "tree_reg = make_pipeline(preprocessing, DecisionTreeRegressor(random_state=42))\n",
    "\n",
    "# Train the model on the training data\n",
    "tree_reg.fit(accidentsTrain, accidentsTrain_labels)\n",
    "\n",
    "# Make predictions and calculate RMSE\n",
    "predictions = tree_reg.predict(accidentsTrain)\n",
    "tree_rmse = root_mean_squared_error(accidentsTrain_labels, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    10.000000\n",
       "mean      0.058139\n",
       "std       0.018787\n",
       "min       0.037425\n",
       "25%       0.044544\n",
       "50%       0.053367\n",
       "75%       0.069773\n",
       "max       0.089090\n",
       "dtype: float64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import cross_val_score for cross-validation evaluation\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# Perform 10-fold cross-validation on the decision tree regressor model\n",
    "# The scoring parameter is set to \"neg_root_mean_squared_error\", which returns the negative RMSE (for minimization).\n",
    "# The negative sign is used because cross_val_score maximizes the score, so we negate RMSE to follow that convention.\n",
    "tree_rmses = -cross_val_score(tree_reg, accidentsTrain, accidentsTrain_labels,\n",
    "                              scoring=\"neg_root_mean_squared_error\", cv=10)\n",
    "\n",
    "# Convert the RMSE values to a pandas Series and display statistical summary (mean, std, etc.)\n",
    "# This gives us an overview of how the model performs across different folds of the cross-validation.\n",
    "pd.Series(tree_rmses).describe()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Random Forest Regressor\n",
    "Random Forest Regressor is an ensemble method that combines multiple decision trees. This model tends to perform better than a single decision tree and is more robust to overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.01791849140226002"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# Initialize the random forest regressor model\n",
    "full_pipeline = Pipeline([\n",
    "    (\"preprocessing\", preprocessing),\n",
    "    (\"random_forest\", RandomForestRegressor(random_state=42)),\n",
    "])\n",
    "\n",
    "# Train the model on the training data\n",
    "full_pipeline.fit(accidentsTrain, accidentsTrain_labels)\n",
    "\n",
    "# Make predictions with the trained random forest model\n",
    "predictions_rf = full_pipeline.predict(accidentsTrain)\n",
    "\n",
    "# Calculate RMSE by taking the square root of the Mean Squared Error (MSE)\n",
    "rmse_rf = root_mean_squared_error(accidentsTrain_labels, predictions_rf)\n",
    "\n",
    "# Output the RMSE for the Random Forest model\n",
    "rmse_rf\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving the Model\n",
    "\n",
    "Once the model is trained and evaluated, it's important to save it for later use. This allows you to load the model without retraining it, making predictions on new data quickly.\n",
    "\n",
    "### 1. **Saving the Model Using `joblib`**\n",
    "\n",
    "In this step, we save the trained model pipeline, which includes both the preprocessing steps and the Random Forest model. The model is stored in a `.pkl` file, which can be loaded later for inference or further evaluation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Traffic_Accident_Injury_Predictor_Model.pkl']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "# Save the entire model pipeline (preprocessing + Random Forest)\n",
    "joblib.dump(full_pipeline, \"Traffic_Accident_Injury_Predictor_Model.pkl\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
